{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nWe are predicting whether a given transaction is considered fraud or not, as indicated by the isFraud column\\nin train_transaction.\\n\\nNot all transactions have corresponding identity information.\\n\\n\\nGeneral information about the meaning of the data features from the competition discussion:\\n\\nTransaction Table *\\nTransactionDT: timedelta from a given reference datetime (not an actual timestamp)\\nTransactionAMT: transaction payment amount in USD\\nProductCD: product code, the product for each transaction\\ncard1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\\naddr: address\\ndist: distance\\nP_ and (R__) emaildomain: purchaser and recipient email domain\\nC1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\\nD1-D15: timedelta, such as days between previous transaction, etc.\\nM1-M9: match, such as names on card and address, etc.\\nVxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\\nCategorical Features:\\nProductCD\\ncard1 - card6\\naddr1, addr2\\nP_emaildomain\\nR_emaildomain\\nM1 - M9\\n\\nIdentity Table *\\nVariables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions.\\nThey're collected by Vesta’s fraud protection system and digital security partners.\\n(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\\n\\nCategorical Features:\\nDeviceType\\nDeviceInfo\\nid_12 - id_38\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CAP 5610 Project\n",
    "# Dataset Link: https://www.kaggle.com/c/ieee-fraud-detection\n",
    "# Feature Engineering: https://www.kaggle.com/c/ieee-fraud-detection/discussion/108575\n",
    "# https://www.kaggle.com/kenjee/titanic-project-example \n",
    "# evaluation metrics: https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "train_identity = pd.read_csv(os.getcwd() + \"\\\\train_identity.csv\")\n",
    "train_transaction = pd.read_csv(os.getcwd() + \"\\\\train_transaction.csv\")\n",
    "\n",
    "# print(train_identity.head())\n",
    "# print(train_transaction.head())\n",
    "\n",
    "'''\n",
    "\n",
    "We are predicting whether a given transaction is considered fraud or not, as indicated by the isFraud column\n",
    "in train_transaction.\n",
    "\n",
    "Not all transactions have corresponding identity information.\n",
    "\n",
    "\n",
    "General information about the meaning of the data features from the competition discussion:\n",
    "\n",
    "Transaction Table *\n",
    "TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "TransactionAMT: transaction payment amount in USD\n",
    "ProductCD: product code, the product for each transaction\n",
    "card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "addr: address\n",
    "dist: distance\n",
    "P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "M1-M9: match, such as names on card and address, etc.\n",
    "Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n",
    "Categorical Features:\n",
    "ProductCD\n",
    "card1 - card6\n",
    "addr1, addr2\n",
    "P_emaildomain\n",
    "R_emaildomain\n",
    "M1 - M9\n",
    "\n",
    "Identity Table *\n",
    "Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions.\n",
    "They're collected by Vesta’s fraud protection system and digital security partners.\n",
    "(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n",
    "\n",
    "Categorical Features:\n",
    "DeviceType\n",
    "DeviceInfo\n",
    "id_12 - id_38\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144233 entries, 0 to 144232\n",
      "Data columns (total 41 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   TransactionID  144233 non-null  int64  \n",
      " 1   id_01          144233 non-null  float64\n",
      " 2   id_02          140872 non-null  float64\n",
      " 3   id_03          66324 non-null   float64\n",
      " 4   id_04          66324 non-null   float64\n",
      " 5   id_05          136865 non-null  float64\n",
      " 6   id_06          136865 non-null  float64\n",
      " 7   id_07          5155 non-null    float64\n",
      " 8   id_08          5155 non-null    float64\n",
      " 9   id_09          74926 non-null   float64\n",
      " 10  id_10          74926 non-null   float64\n",
      " 11  id_11          140978 non-null  float64\n",
      " 12  id_12          144233 non-null  object \n",
      " 13  id_13          127320 non-null  float64\n",
      " 14  id_14          80044 non-null   float64\n",
      " 15  id_15          140985 non-null  object \n",
      " 16  id_16          129340 non-null  object \n",
      " 17  id_17          139369 non-null  float64\n",
      " 18  id_18          45113 non-null   float64\n",
      " 19  id_19          139318 non-null  float64\n",
      " 20  id_20          139261 non-null  float64\n",
      " 21  id_21          5159 non-null    float64\n",
      " 22  id_22          5169 non-null    float64\n",
      " 23  id_23          5169 non-null    object \n",
      " 24  id_24          4747 non-null    float64\n",
      " 25  id_25          5132 non-null    float64\n",
      " 26  id_26          5163 non-null    float64\n",
      " 27  id_27          5169 non-null    object \n",
      " 28  id_28          140978 non-null  object \n",
      " 29  id_29          140978 non-null  object \n",
      " 30  id_30          77565 non-null   object \n",
      " 31  id_31          140282 non-null  object \n",
      " 32  id_32          77586 non-null   float64\n",
      " 33  id_33          73289 non-null   object \n",
      " 34  id_34          77805 non-null   object \n",
      " 35  id_35          140985 non-null  object \n",
      " 36  id_36          140985 non-null  object \n",
      " 37  id_37          140985 non-null  object \n",
      " 38  id_38          140985 non-null  object \n",
      " 39  DeviceType     140810 non-null  object \n",
      " 40  DeviceInfo     118666 non-null  object \n",
      "dtypes: float64(23), int64(1), object(17)\n",
      "memory usage: 45.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nAll columns in train_identity seem like categorical data. More specifically, they are nominal. However, the description \\nprovided of the features in train_identity states that DeviceType, DeviceInfo, and id_12 - id_38 are the only features \\nthat are categorical. Will inspect id_01-id_11 to confirm their type.\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_identity.info()\n",
    "\n",
    "'''\n",
    "\n",
    "All columns in train_identity seem like categorical data. More specifically, they are nominal. However, the description \n",
    "provided of the features in train_identity states that DeviceType, DeviceInfo, and id_12 - id_38 are the only features \n",
    "that are categorical. Will inspect id_01-id_11 to confirm their type.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 590540 entries, 0 to 590539\n",
      "Columns: 394 entries, TransactionID to V339\n",
      "dtypes: float64(376), int64(4), object(14)\n",
      "memory usage: 1.7+ GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\ntrain_transaction contains a mix of categorical and numeric data. \\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transaction.info()\n",
    "'''\n",
    "\n",
    "train_transaction contains a mix of categorical and numeric data. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# replace null values with -999\n",
    "train_identity = train_identity.fillna(value = -999)\n",
    "train_transaction = train_transaction.fillna(value = -999)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# convert non-numeric columns to numeric by assigning each class to a number\n",
    "number = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in list(train_identity):\n",
    "    if (train_identity[col].dtype == \"object\"):\n",
    "        train_identity[col] = train_identity[col].astype(str)\n",
    "        train_identity[col] = number.fit_transform(train_identity[col])\n",
    "        \n",
    "for col in list(train_transaction):\n",
    "    if (train_transaction[col].dtype == \"object\"):\n",
    "        train_transaction[col] = train_transaction[col].astype(str)\n",
    "        train_transaction[col] = number.fit_transform(train_transaction[col])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not all transactions have corresponding identity data, so only include those with identity data\n",
    "# df = pd.merge(train_identity, train_transaction, on = \"TransactionID\", how = \"left\")\n",
    "\n",
    "# not all transactions have corresponding identity data, so for instances with no corresponding idenity data, fill with \n",
    "# dummy values\n",
    "df = pd.merge(train_identity, train_transaction, on = \"TransactionID\", how = \"outer\")\n",
    "df = df.fillna(value = -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([\"isFraud\"], axis = 1).values\n",
    "\n",
    "y = df[\"isFraud\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(criterion = \"entropy\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.9795915602668744\n",
      "Confusion matrix: \n",
      "[[142296    129]\n",
      " [  2884   2326]]\n",
      "The precision score is 0.9474541751527495\n",
      "The recall score is 0.44644913627639154\n",
      "The F1 score is 0.6069145466405741\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"The accuracy score is \" + str(accuracy_score(y_test, predicted)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Confusion matrix: \")\n",
    "print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(\"The precision score is \" + str(precision_score(y_test, predicted)))\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"The recall score is \" + str(recall_score(y_test, predicted)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"The F1 score is \" + str(f1_score(y_test, predicted)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
